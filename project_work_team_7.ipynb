{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0aegAFNihDz"
      },
      "source": [
        "# Text Mining Project Work (Team 7)\n",
        "\n",
        "**Toxic Comment Classification with Naive Bayes and DistilBERT**\n",
        "\n",
        "_Prof. Gianluca Moro, Prof. Giacomo Frisoni – DISI, University of Bologna_\n",
        "\n",
        "name.surname@unibo.it\n",
        "\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOBjMeN9i6TV"
      },
      "source": [
        "## Instructions\n",
        "- The provided exercises must be executed by the students of Team 7.\n",
        "- At the end, the file must contain all the required results (as code cell outputs) along with all the commands necessary to reproduce them.\n",
        "- The function of every command or group of related commands must be documented clearly and concisely.\n",
        "- The submission deadline is March 18th, 2024.\n",
        "- When finished, one team member will send the notebook file (having .ipynb extension) via mail (using your BBS email account) to the teacher (giacomo.frisoni@unibo.it) indicating “[BBS Teamwork] Your last names” as subject, also keeping an own copy of the file for safety.\n",
        "- You are allowed to consult the teaching material and to search the Web for quick reference.\n",
        "- If still in doubt about anything, ask the teacher.\n",
        "- It is severely NOT allowed to communicate with other teams. Ask the teacher for any clarification about the exercises.\n",
        "- Each correctly developed point counts 2/30."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U51JJBSVeIvz"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq-rJLYrfGho"
      },
      "source": [
        "Run the following cells to import some necessary packages and download all the needed files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PnCN7H1geyyf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fu_7tBMOepHM"
      },
      "outputs": [],
      "source": [
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "urxyu9RweWo8"
      },
      "outputs": [],
      "source": [
        "download(\"reviews-electronics.csv.gz\", \"https://www.dropbox.com/s/5aidj1ns3wiuchi/reviews-electronics.csv.gz?dl=1\")\n",
        "download(\"reviews-home.csv.gz\", \"https://www.dropbox.com/s/9dlvc0nntibibk3/reviews-home.csv.gz?dl=1\")\n",
        "download(\"reviews-books.csv.gz\", \"https://www.dropbox.com/s/otbdd2u7x9ylzku/reviews-books.csv.gz?dl=1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_PZbKB6qfM0G"
      },
      "outputs": [],
      "source": [
        "download(\"positive-words.txt\", \"https://www.dropbox.com/s/pmju477pv8ayzho/positive-words.txt?dl=1\")\n",
        "download(\"negative-words.txt\", \"https://www.dropbox.com/s/yy4l1ezlrsar8cf/negative-words.txt?dl=1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGpnMs2eKMB"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBSt1y2agFE9"
      },
      "source": [
        "**1)** Load the dataset from the file `reviews-electronics.csv.gz` into a new dataframe named `reviews_A`. Next, import the dataset from the file `reviews-home.csv.gz` into a new dataframe named `reviews_B`, and from the file `reviews-books.csv.gz` into a new dataframe named `reviews_C`. Lastly, extract the opinion word lists from the files `positive-words.txt` and `negative-words.txt`, assigning them to two new variables `pos_words` and `neg_words` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oOn21wHfi8at"
      },
      "outputs": [],
      "source": [
        "# Load dataset from reviews-electronics.csv.gz into reviews_A dataframe\n",
        "reviews_A = pd.read_csv('reviews-electronics.csv.gz', sep='\\t', engine='python')\n",
        "\n",
        "# Import dataset from reviews-home.csv.gz into reviews_B dataframe\n",
        "reviews_B = pd.read_csv('reviews-home.csv.gz', sep='\\t', engine='python')\n",
        "\n",
        "# Import dataset from reviews-books.csv.gz into reviews_C dataframe\n",
        "reviews_C = pd.read_csv('reviews-books.csv.gz', sep='\\t', engine='python')\n",
        "\n",
        "# Extract opinion word lists from positive-words.txt and negative-words.txt\n",
        "def extract_opinion_words(file):\n",
        "    with open(file, 'r', encoding='latin1') as f:\n",
        "        words = f.read().splitlines()\n",
        "    return words\n",
        "\n",
        "pos_words = extract_opinion_words('positive-words.txt')\n",
        "neg_words = extract_opinion_words('negative-words.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJADgDZFihEG"
      },
      "source": [
        "**2)** Print the first five rows of the three `reviews_X` datasets. Then, print their cardinality and the distribution of the `label` feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc2HsrsEi8aw",
        "outputId": "8af29512-b0b2-4d86-ca27-200ef4728a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five rows of reviews_A:\n",
            "  label                                               text\n",
            "0   pos  We got this GPS for my husband who is an (OTR)...\n",
            "1   neg  I'm a professional OTR truck driver, and I bou...\n",
            "2   pos  This adaptor is real easy to setup and use rig...\n",
            "3   neg  I've had mine for a year and here's what we go...\n",
            "4   pos  This product really works great but I found th...\n",
            "\n",
            "First five rows of reviews_B:\n",
            "  label                                               text\n",
            "0   pos  This book is a must have if you get a Zoku (wh...\n",
            "1   neg  I did sloppy shopping. This machine is exactly...\n",
            "2   pos  This book is so beautifully illustrated and ea...\n",
            "3   neg  If you type the wrong word in, it &#34;might&#...\n",
            "4   pos  This beautifully illustrated book featuring te...\n",
            "\n",
            "First five rows of reviews_C:\n",
            "  label                                               text\n",
            "0   pos  This is one my must have books. It is a master...\n",
            "1   neg  As Amin Rihani described his own friend Gibran...\n",
            "2   pos  This book provides a reflection that you can a...\n",
            "3   neg  I appreciate getting the book at the great pri...\n",
            "4   pos  I first read THE PROPHET in college back in th...\n",
            "\n",
            "Cardinality of reviews_A: 10000\n",
            "\n",
            "Cardinality of reviews_B: 10000\n",
            "\n",
            "Cardinality of reviews_C: 10000\n",
            "\n",
            "Distribution of label feature in reviews_A:\n",
            "pos    5000\n",
            "neg    5000\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Distribution of label feature in reviews_B:\n",
            "pos    5000\n",
            "neg    5000\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Distribution of label feature in reviews_C:\n",
            "pos    5000\n",
            "neg    5000\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Print the first five rows of reviews_A dataset\n",
        "print(\"First five rows of reviews_A:\")\n",
        "print(reviews_A.head(5))\n",
        "\n",
        "# Print the first five rows of reviews_B dataset\n",
        "print(\"\\nFirst five rows of reviews_B:\")\n",
        "print(reviews_B.head(5))\n",
        "\n",
        "# Print the first five rows of reviews_C dataset\n",
        "print(\"\\nFirst five rows of reviews_C:\")\n",
        "print(reviews_C.head(5))\n",
        "\n",
        "# Print the cardinality of reviews_A dataset\n",
        "print(\"\\nCardinality of reviews_A:\", len(reviews_A))\n",
        "\n",
        "# Print the cardinality of reviews_B dataset\n",
        "print(\"\\nCardinality of reviews_B:\", len(reviews_B))\n",
        "\n",
        "# Print the cardinality of reviews_C dataset\n",
        "print(\"\\nCardinality of reviews_C:\", len(reviews_C))\n",
        "\n",
        "# Print the distribution of the label feature in reviews_A dataset\n",
        "print(\"\\nDistribution of label feature in reviews_A:\")\n",
        "print(reviews_A['label'].value_counts())\n",
        "\n",
        "# Print the distribution of the label feature in reviews_B dataspad_sequenceset\n",
        "print(\"\\nDistribution of label feature in reviews_B:\")\n",
        "print(reviews_B['label'].value_counts())\n",
        "\n",
        "# Print the distribution of the label feature in reviews_C dataset\n",
        "print(\"\\nDistribution of label feature in reviews_C:\")\n",
        "print(reviews_C['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXg0Vw1kihEX"
      },
      "source": [
        "**3)** Divide the `reviews_A` dataset into a train set and a test set by choosing the initial half of reviews for training and the latter half for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNmuSV1Ti8ay",
        "outputId": "e90790aa-5553-4789-c16a-3ca40aebf454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train set:  5000\n",
            "Size of test set:  5000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide the reviews_A dataset into train and test sets\n",
        "train_reviews_A, test_reviews_A = train_test_split(reviews_A, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the sizes of the train and test sets\n",
        "print(\"Size of train set: \", len(train_reviews_A))\n",
        "print(\"Size of test set: \", len(test_reviews_A))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c357B6OmihEY"
      },
      "source": [
        "**4)** Classify the reviews in the `reviews_A` test set by first assigning to each instance a score equal to the sum of scores of known words within it. Then, return `\"pos\"` for reviews with a positive score, and `\"neg\"` for reviews with a negative or neutral score.\n",
        "\n",
        "Score each word:\n",
        " - -1 if it is found in negative words list\n",
        " - -2 if it is found in negative word list and it is preceded by the word \"very\"\n",
        " - +1 if it is found in positive words list\n",
        " - +2 if it is found in positive word list and it is preceded by the word \"very\"\n",
        "\n",
        "Start with the setup of NLTK and the definition of the scoring function.\n",
        "Then, apply the function to all the instances in the `reviews_A` test set.\n",
        "Finally, compare the obtained labels with the known ones and compute the accuracy as the ratio of matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTYnBKBbi8a1",
        "outputId": "ac667b0f-0d1b-4de4-decd-043674150f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7204\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Setup NLTK\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define scoring function\n",
        "def score_review(review):\n",
        "    score = 0\n",
        "    words = word_tokenize(review.lower())\n",
        "    for i in range(len(words)):\n",
        "        if words[i] in neg_words:\n",
        "            if i > 0 and words[i-1] == 'very':\n",
        "                score -= 2\n",
        "            else:\n",
        "                score -= 1\n",
        "        elif words[i] in pos_words:\n",
        "            if i > 0 and words[i-1] == 'very':\n",
        "                score += 2\n",
        "            else:\n",
        "                score += 1\n",
        "    return score\n",
        "\n",
        "# Apply scoring function to reviews_A test set\n",
        "predicted_labels = []\n",
        "for review in reviews_A['text']:\n",
        "    score = score_review(review)\n",
        "    if score > 0:\n",
        "        predicted_labels.append('pos')\n",
        "    else:\n",
        "        predicted_labels.append('neg')\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyroDWVoihEz"
      },
      "source": [
        "**5)** Create a pipeline including a `CountVectorizer` to convert reviews into word count vectors (excluding words that appear in less than 3 documents) and a `LogisticRegression` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kF0eOTMli8a4"
      },
      "outputs": [],
      "source": [
        "# Create the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(min_df=3)),\n",
        "    ('classifier', LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qy6cAiuihE5"
      },
      "source": [
        "**6)** Train the model on all `reviews_B` data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "SF0g7pECi8a5",
        "outputId": "4d6726a5-7a49-491f-c03b-f7d55c36503c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', CountVectorizer(min_df=3)),\n",
              "                ('classifier', LogisticRegression())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(min_df=3)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(min_df=3)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=3)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pipeline.fit(reviews_B['text'], reviews_B['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdC3yKxxihFC"
      },
      "source": [
        "**7)** Evaluate the model on the `reviews_A` test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SwOL_Izi8a7",
        "outputId": "9a4dc21a-c896-4961-becf-f9f7faff0997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8498\n"
          ]
        }
      ],
      "source": [
        "predicted_labels = pipeline.predict(reviews_A['text'])\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crs7chcBihFP"
      },
      "source": [
        "**8)** Create a new pipeline as above, but replacing the `CountVectorizer` with a `TfidfVectorizer`, and the `LogisticRegression` model with a `MultinomialNB` one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hAHuLKrZi8a8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create the new pipeline\n",
        "new_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(min_df=3)),\n",
        "    ('classifier', MultinomialNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd320SxXu6_9"
      },
      "source": [
        "**9)** Train the new pipeline on all the `reviews_B` data and evaluate the resulting model on the `reviews_A` test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNuGcQlJi8a-",
        "outputId": "0ff73e5f-4973-4610-fd7c-555a7e701bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7254\n"
          ]
        }
      ],
      "source": [
        "# Train the new pipeline on all the reviews_B data\n",
        "new_pipeline.fit(reviews_B['text'], reviews_B['label'])\n",
        "\n",
        "# Evaluate the resulting model on the reviews_A test set\n",
        "predicted_labels = new_pipeline.predict(reviews_A['text'])\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SCmzFpYihFm"
      },
      "source": [
        "**10)** Repeat points (8) and (9) but set the `ngram_range` parameter of the `TfidfVectorizer` to use only bigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxK4ZSg1i8a-",
        "outputId": "399d2aad-7dfa-414a-f7fa-2f56146b6017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8478\n"
          ]
        }
      ],
      "source": [
        "# Create the new pipeline with bigram n-grams\n",
        "new_pipeline_bigram = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(min_df=3, ngram_range=(2, 2))),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train the new pipeline on all the reviews_B data\n",
        "new_pipeline_bigram.fit(reviews_B['text'], reviews_B['label'])\n",
        "\n",
        "# Evaluate the resulting model on the reviews_A test set\n",
        "predicted_labels_bigram = new_pipeline_bigram.predict(reviews_A['text'])\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels_bigram == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z8-7qwTihF4"
      },
      "source": [
        "**11)** Repeat the evaluation of the three models above, this time on the `reviews_C` data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js_LNAxGi8a_",
        "outputId": "9138d890-d69d-4337-be30-c2e8db0f969e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for first model:  0.6997\n",
            "Accuracy for second model:  0.7199\n",
            "Accuracy for third model:  0.7243\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the first pipeline on the reviews_C dataset\n",
        "predicted_labels_first = pipeline.predict(reviews_C['text'])\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels_first == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy for first model: \", accuracy)\n",
        "\n",
        "# Evaluate the second pipeline on the reviews_C dataset\n",
        "predicted_labels_second = new_pipeline.predict(reviews_C['text'])\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels_second == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy for second model: \", accuracy)\n",
        "\n",
        "# Evaluate the third pipeline on the reviews_C dataset\n",
        "predicted_labels_third = new_pipeline_bigram.predict(reviews_C['text'])\n",
        "\n",
        "# Compare predicted labels with known labels and compute accuracy\n",
        "matches = sum(predicted_labels_third == reviews_A['label'])\n",
        "accuracy = matches / len(reviews_A)\n",
        "\n",
        "print(\"Accuracy for third model: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_OB8HmTMN7F"
      },
      "source": [
        "**12)** Tokenize the `reviews_A` train instances and use them to build a 300-dimensional Word2Vec vector space using a window size equals to 5 and excluding all the terms that appear less than 7 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y5S8thoKi8bA"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenize the reviews_A train instances\n",
        "tokenized_reviews = [word_tokenize(review) for review in train_reviews_A['text']]\n",
        "\n",
        "# Build the Word2Vec model\n",
        "word2vec_model = Word2Vec(tokenized_reviews, vector_size=300, window=5, min_count=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp6hj-G5zPAd"
      },
      "source": [
        "**13)** Convert the tokenized training reviews into a list of lists of term indices in the Word2Vec model, leaving out terms not present in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fkPlu7e1i8bB"
      },
      "outputs": [],
      "source": [
        "term_indices = []\n",
        "for review in tokenized_reviews:\n",
        "    indices = [word2vec_model.wv.key_to_index[word] for word in review if word in word2vec_model.wv.key_to_index] # The \"if\" statement filters out words that are not present in the word2vec model's vocabulary, ensuring that only valid words are used to retrieve their corresponding indices.\n",
        "    term_indices.append(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkEokwmktSlW"
      },
      "source": [
        "**14)** Make all index sequences of the same length (250 words for each review), trimming longer sequences to that size and padding shorter sequences with zero values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BQfnXK8Ii8bB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_sequence_length = 250\n",
        "\n",
        "# Pad sequences to the maximum length\n",
        "padded_sequences = pad_sequences(term_indices, maxlen=max_sequence_length, padding='post', truncating='post', value=0)\n",
        "# padding=” post”: add the zeros at the end of the sequence to make the samples in the same size\n",
        "# truncating=”post” setting this truncating parameter as post means that when a sentence exceeds the number of maximum words drop the last words in the sentence instead of the default setting which drops the words from the beginning of the sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-tIxApgv00-"
      },
      "source": [
        "**15)** Train an LSTM or GRU neural network of your choice on the training sequences defined above. Finally, assess the neural network on `reviews_A` test reviews. Try to maximize the accuracy on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ret9fHQi8bD",
        "outputId": "ac9e67cb-e437-4b16-bd3b-064d62910185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 38s 281ms/step - loss: 0.6988 - accuracy: 0.5038 - val_loss: 0.6950 - val_accuracy: 0.4820\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 36s 292ms/step - loss: 0.6851 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5050\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 34s 275ms/step - loss: 0.6707 - accuracy: 0.5580 - val_loss: 0.6431 - val_accuracy: 0.6840\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 35s 284ms/step - loss: 0.6121 - accuracy: 0.6992 - val_loss: 0.5725 - val_accuracy: 0.7250\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 33s 265ms/step - loss: 0.5300 - accuracy: 0.7623 - val_loss: 0.5525 - val_accuracy: 0.7370\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 37s 295ms/step - loss: 0.4770 - accuracy: 0.7955 - val_loss: 0.5187 - val_accuracy: 0.7570\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 40s 321ms/step - loss: 0.4516 - accuracy: 0.8030 - val_loss: 0.5152 - val_accuracy: 0.7690\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 39s 312ms/step - loss: 0.4265 - accuracy: 0.8225 - val_loss: 0.5046 - val_accuracy: 0.7710\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 33s 266ms/step - loss: 0.4044 - accuracy: 0.8355 - val_loss: 0.5027 - val_accuracy: 0.7710\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 32s 256ms/step - loss: 0.3759 - accuracy: 0.8482 - val_loss: 0.4738 - val_accuracy: 0.7900\n",
            "313/313 [==============================] - 37s 118ms/step - loss: 0.4107 - accuracy: 0.8231\n",
            "Accuracy:  0.8230999708175659\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "\n",
        "# Setting the seed\n",
        "seed(99)\n",
        "tf.random.set_seed(99)\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder() # Using LabelEncoder to convert categorical data into numerical format.\n",
        "encoded_labels = label_encoder.fit_transform(train_reviews_A['label'])\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential() # Sequential model is used to create a linear stack of layers for building the neural network architecture.\n",
        "lstm_model.add(Embedding(len(word2vec_model.wv.key_to_index), 300, input_length=max_sequence_length, weights=[word2vec_model.wv.vectors], trainable=False))\n",
        "lstm_model.add(LSTM(64)) # LSTM is chosen here over GRU for potential advantages in capturing long-term dependencies in sequential data.\n",
        "lstm_model.add(Dense(1, activation='sigmoid')) # Using sigmoid activation function and a single-node dense layer for binary classification task.\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Binary cross-entropy is used as the loss function because it is suitable for binary classification tasks, effectively measuring the difference between predicted and true binary outcomes.\n",
        "\n",
        "# Train the model\n",
        "lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32) # Validation data is used to evaluate the model's performance on unseen data during training, helping to monitor for overfitting and providing insights into generalization capability.\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_sequences = [word_tokenize(review) for review in reviews_A['text']]\n",
        "test_term_indices = []\n",
        "for review in test_sequences:\n",
        "    indices = [word2vec_model.wv.key_to_index[word] for word in review if word in word2vec_model.wv.key_to_index] # The \"if\" statement filters out words that are not present in the word2vec model's vocabulary, ensuring that only valid words are used to retrieve their corresponding indices.\n",
        "    test_term_indices.append(indices)\n",
        "\n",
        "padded_test_sequences = pad_sequences(test_term_indices, maxlen=max_sequence_length, padding='post', truncating='post', value=0)\n",
        "encoded_test_labels = label_encoder.transform(reviews_A['label'])\n",
        "loss, accuracy = lstm_model.evaluate(padded_test_sequences, encoded_test_labels)\n",
        "\n",
        "# After experimentation, lowering the number of hidden layers in the LSTM from 128 to 64 and setting the seed to 99 can improve accuracy up to 0.8\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}